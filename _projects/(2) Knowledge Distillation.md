---
name: Knowledge Distillation
tools: [Transformers, Pytorch, Tensorboard]
image: ../assets/projects/2.jpeg
description: A general knowledge distillation pipeline created for the transformers library, which aids in reducing the inference time and size of large deep learning models with minimal loss in accuracy
external_url: https://github.com/mayankmusaddi/general-distillation
---